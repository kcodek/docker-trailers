version: "3.7"
services:
  web:
    # replace username/repo:tag with your name and image details
    image: ksignk/get-started:part_2
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: "0.1"
          memory: 50M
      restart_policy:
        condition: on-failure
    ports:
      - "4000:80"
    networks:
      - webnet

  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - "8080:8080"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      placement:
        constraints: [node.role == manager]
    networks:
      - webnet

  redis:
    image: redis
    ports:
      - "6379:6379"
    volumes:
      - "/home/docker/data:/data"
    deploy:
      placement:
        constraints: [node.role == manager]
    command: redis-server --appendonly yes
    networks:
      - webnet  

networks:
  webnet:

# This docker-compose.yml file tells Docker to do the following:
  # Pull the image we uploaded in step 2 from the registry.
  # Run 3 instances of that image as a service called web, limiting each one to use, at most, 10% of a single core of CPU time (this could also be e.g. “1.5” to mean 1 and half core for each), and 50MB of RAM.
  # Immediately restart containers if one fails.
  # Map port 4000 on the host to web’s port 80.
  # Instruct web’s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves publish to web’s port 80 at an ephemeral port.)
  # Define the webnet network with the default settings (which is a load-balanced overlay network).

# The only thing new here is the peer service to web, named visualizer. 
# Notice two new things here: 
  # - a volumes key, giving the visualizer access to the host’s socket file for Docker, and
  # - a placement key, ensuring that this service only ever runs on a swarm manager -- never a worker.
    # That’s because this container, built from an open source project created by Docker, displays Docker services running on a swarm in a diagram.


# Redis has an official image in the Docker library and has been granted the short image name of just redis, so no username/repo notation here. 
# The Redis port, 6379, has been pre-configured by Redis to be exposed from the container to the host, and here in our Compose file we expose it from the host to the world, 
# so you can actually enter the IP for any of your nodes into Redis Desktop Manager and manage this Redis instance, if you so choose.

# Most importantly, there are a couple of things in the redis specification that make data persist between deployments of this stack:
# redis always runs on the manager, so it’s always using the same filesystem.
# redis accesses an arbitrary directory in the host’s file system as /data inside the container, which is where Redis stores data.
# Together, this is creating a “source of truth” in your host’s physical filesystem for the Redis data. 
# Without this, Redis would store its data in /data inside the container’s filesystem, which would get wiped out if that container were ever redeployed.

# This source of truth has two components:
# The placement constraint you put on the Redis service, ensuring that it always uses the same host.
# The volume you created that lets the container access ./data (on the host) as /data (inside the Redis container). 
# While containers come and go, the files stored on ./data on the specified host persists, enabling continuity.
